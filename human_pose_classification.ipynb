{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abe2678",
   "metadata": {},
   "source": [
    "# Human Pose Classification Using Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f52a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Bingsu/Human_Action_Recognition\", split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64d2cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle().train_test_split(test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc778f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]['image']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e66d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset['train'].features['labels'].names\n",
    "\n",
    "label2id, id2label = dict(), dict()\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1cd80c",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor #-> like Tokenizer\n",
    "\n",
    "model_ckpt = \"google/vit-base-patch16-224-in21k\"\n",
    "# model_ckpt = \"microsoft/swinv2-tiny-patch4-window16-256\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654517fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_ckpt, use_fast=True)\n",
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "\n",
    "size = (image_processor.size['shortest_edge'] if 'shortest_edge' in image_processor.size \n",
    "        else (image_processor.size['height'], image_processor.size['width']))\n",
    "\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])\n",
    "\n",
    "def transforms(batch):\n",
    "    batch['pixel_values'] = [_transforms(img.convert('RGB')) for img in batch['image']]\n",
    "\n",
    "    del batch['image']\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471f72a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.with_transform(transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09832b18",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36923b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install evaluate\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27c7ff5",
   "metadata": {},
   "source": [
    "#  Vision Transformer (ViT) Fine Tuning for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8398327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ceb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    num_labels = len(labels),\n",
    "    id2label = id2label,\n",
    "    label2id = label2id\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e996b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a06f36b",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b05ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"train_dir\",\n",
    "    remove_unused_columns=False,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy'\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args=args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b641102",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f851a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eaae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('vit-human-pose-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f8344d",
   "metadata": {},
   "source": [
    "# Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3870885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f21a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = trainer.predict(dataset['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdbacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = logits.predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7782a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe66428",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm, annot=True, xticklabels=label2id.keys(), yticklabels=label2id.keys(), fmt='d', cbar=False, cmap='Reds')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e79ba2",
   "metadata": {},
   "source": [
    "# Prediction on Real Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebcee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoImageProcessor\n",
    "\n",
    "model_ckpt = \"google/vit-base-patch16-224-in21k\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_ckpt, use_fast=True)\n",
    "\n",
    "pipe = pipeline('image-classification', model='vit-human-pose-classification', \n",
    "                image_processor=image_processor)\n",
    "\n",
    "url = \"https://images.pexels.com/photos/1755385/pexels-photo-1755385.jpeg\"\n",
    "\n",
    "output = pipe(url)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c632e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor.save_pretrained('vit-human-pose-classification')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d689f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and image processor from the local directory\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "local_directory = 'vit-human-pose-classification'\n",
    "image_processor = AutoImageProcessor.from_pretrained(local_directory, use_fast=True)\n",
    "model = AutoModel.from_pretrained(local_directory, local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df9cf54",
   "metadata": {},
   "source": [
    "# Push Model to AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8bfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "\n",
    "# s3 = boto3.client('s3')\n",
    "\n",
    "# bucket_name = 'mlopssentimentanalysis-8989'\n",
    "\n",
    "# def create_bucket(bucket_name):\n",
    "#     response = s3.list_buckets()\n",
    "#     buckets = [buck['Name'] for buck in response['Buckets']]\n",
    "#     if bucket_name not in buckets:\n",
    "#         s3.create_bucket(Bucket=bucket_name)\n",
    "#         print(\"Bucket is created\")\n",
    "\n",
    "#     else:\n",
    "#         print(\"Bucket already exists in your account!!! Feel free to use it.\")\n",
    "\n",
    "# create_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload model folder to s3 bucket ml-models/vit-human-pose-classification\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'mlops-44448888'\n",
    "\n",
    "def upload_directory(directory_path, s3_prefix):\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file).replace(\"\\\\\", \"/\")\n",
    "            relpath = os.path.relpath(file_path, directory_path)\n",
    "            s3_key = os.path.join(s3_prefix, relpath).replace(\"\\\\\", \"/\")\n",
    "            \n",
    "            s3.upload_file(file_path, bucket_name, s3_key)\n",
    "\n",
    "\n",
    "upload_directory('vit-human-pose-classification', 'ml-models/vit-human-pose-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df070af8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
